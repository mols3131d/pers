{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... \n",
      "Found conflicts! Looking for incompatible packages.\n",
      "This can take several minutes.  Press CTRL-C to abort.\n",
      "failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building graph of deps:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Examining @/win-64::__win==0=0:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Examining conda-forge/win-64::python==3.10.8=h0269646_0_cpython:  20%|██        | 1/5 [00:00<?, ?it/s]\n",
      "Examining tensorflow-addons:  40%|████      | 2/5 [00:00<00:00, 222.24it/s]                           \n",
      "Examining @/win-64::__cuda==12.0=0:  60%|██████    | 3/5 [00:00<00:00, 12.35it/s]\n",
      "Examining @/win-64::__cuda==12.0=0:  80%|████████  | 4/5 [00:00<00:00, 16.46it/s]\n",
      "Examining @/win-64::__archspec==1=x86_64:  80%|████████  | 4/5 [00:00<00:00, 16.46it/s]\n",
      "                                                                                       \n",
      "\n",
      "Determining conflicts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Examining conflict for python tensorflow-addons:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                                                                                      \n",
      "\n",
      "UnsatisfiableError: The following specifications were found\n",
      "to be incompatible with the existing python installation in your environment:\n",
      "\n",
      "Specifications:\n",
      "\n",
      "  - tensorflow-addons -> python[version='>=3.6,<3.7.0a0|>=3.7,<3.8.0a0|>=3.8,<3.9.0a0|>=3.9,<3.10.0a0']\n",
      "\n",
      "Your python: conda-forge/win-64::python==3.10.8=h0269646_0_cpython\n",
      "\n",
      "If python is on the left-most side of the chain, that's the version you've asked for.\n",
      "When python appears to the right, that indicates that the thing on the left is somehow\n",
      "not available for the python version you are constrained to. Note that conda will not\n",
      "change your python version to a different minor version unless you explicitly specify\n",
      "that.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# conda\n",
    "\n",
    "!conda install -c esri tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard Library ---- ---- ---- ----\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "print(\"sys.version :\", sys.version)\n",
    "import glob\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "# etc ---- ---- ---- ----\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "import tqdm\n",
    "# if (\"cv2\" in sys.modules) == False:\n",
    "#     !pip install opencv-python\n",
    "import cv2\n",
    "print(\"cv2.__version__ :\", cv2.__version__)\n",
    "\n",
    "\n",
    "\n",
    "# Data ---- ---- ---- ----\n",
    "import numpy as np\n",
    "print(\"np.__version__ :\", np.__version__)\n",
    "import pandas as pd\n",
    "print(\"pd.__version__ :\", pd.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# ML, DL ---- ---- ---- ----\n",
    "import tensorflow as tf\n",
    "print(\"tf.__version__ :\", tf.__version__)\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "import torch\n",
    "print(\"torch.__version__ :\", torch.__version__)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "else:\n",
    "    print(gpu_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▣ env : Windows\n",
      "\n",
      "▣ platform.uname()\n",
      "uname_result(system='Windows', node='Psh-Intel12thI5', release='10', version='10.0.22621', machine='AMD64')\n",
      "\n",
      "▣ data_path\n",
      "./data\n",
      "\n",
      "▣ train_path\n",
      "./data/train.csv\n",
      "\n",
      "▣ test_path\n",
      "./data/test.csv\n"
     ]
    }
   ],
   "source": [
    "# def ---- ---- ---- ----\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def envPath(dict_path=None):\n",
    "    import platform\n",
    "    from pprint import pprint\n",
    "\n",
    "    global root_path\n",
    "    global data_path\n",
    "\n",
    "    if dict_path == None:\n",
    "        dict_path = {\n",
    "            \"Windows\": {\"root_path\": \".\", \"data_path\": \"data\"},\n",
    "            \"Google_Colab\": {\"root_path\": \"../gdrive/MyDrive\", \"data_path\": \"data\"},\n",
    "            \"Kaggle_notebook\": {\"root_path\": \"..\", \"data_path\": \"input\"},\n",
    "        }\n",
    "    # 추후에 dict_path에 Kaggle_notebook이 없으면 추가하는 코드 추가 요망\n",
    "\n",
    "    env = platform.uname().system\n",
    "\n",
    "    if env == \"Windows\":\n",
    "        env = env\n",
    "\n",
    "    elif env == \"Linux\":\n",
    "        import sys\n",
    "\n",
    "        # Google_Colab\n",
    "        if \"google.colab\" in sys.modules:\n",
    "            env = \"Google_Colab\"\n",
    "            from google.colab import drive\n",
    "\n",
    "            drive.mount(\"/gdrive\", force_remount=True)\n",
    "\n",
    "        # Kaggle_notebook\n",
    "        else:\n",
    "            import os\n",
    "\n",
    "            if list(os.walk(\"/kaggle/\"))[0][1] == [\"lib\", \"input\", \"working\"]:\n",
    "                env = \"Kaggle_notebook\"\n",
    "\n",
    "    root_path = dict_path[env][\"root_path\"]\n",
    "    data_path = f\"{root_path}/{dict_path[env]['data_path']}\"\n",
    "    print(\"▣ env :\", env)\n",
    "    print()\n",
    "    print(\"▣ platform.uname()\", \"\\n\", platform.uname(), sep=\"\")\n",
    "    print()\n",
    "    print(\"▣ data_path\", \"\\n\", data_path, sep=\"\")\n",
    "\n",
    "\n",
    "# path ---- ---- ---- ----\n",
    "envPath()\n",
    "train_file = \"train.csv\"\n",
    "test_file = \"test.csv\"\n",
    "\n",
    "train_path = f\"{data_path}/{train_file}\"\n",
    "test_path = f\"{data_path}/{test_file}\"\n",
    "print()\n",
    "print(\"▣ train_path\")\n",
    "print(train_path)\n",
    "print()\n",
    "print(\"▣ test_path\")\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asd1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07badbe185019afce09527cdf66b20ec507f3045aabcc27b0da70607b5630dc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
